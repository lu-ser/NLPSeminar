{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10TwYiQNsPGsztoGPLm13JzJtFTFNN8-u?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvqhgxzQ_Lby",
        "outputId": "0969e87b-d052-41bd-b5b7-bf0529a3353f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pinecone\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2024.12.14)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone\n",
            "Successfully installed pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.16)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.32)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.16 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.32)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.3.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mistralai\n",
            "  Downloading mistralai-1.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.2.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Collecting jsonpath-python>=1.0.6 (from mistralai)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pydantic>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.10.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.8.2)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->mistralai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->mistralai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.0->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.0->mistralai) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.0->mistralai) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.9.0->mistralai) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.5.0-py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: jsonpath-python, mistralai\n",
            "Successfully installed jsonpath-python-1.0.6 mistralai-1.5.0\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (3.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pinecone\n",
        "%pip install langchain\n",
        "%pip install langchain-community\n",
        "%pip install langchain-core\n",
        "%pip install PyPDF2\n",
        "%pip install -qU langchain_mistralai\n",
        "%pip install mistralai\n",
        "%pip install markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wwG-OsS0-1Cl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Dict\n",
        "import pinecone\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from dotenv import load_dotenv\n",
        "import getpass\n",
        "from langchain_mistralai import ChatMistralAI,MistralAIEmbeddings\n",
        "from mistralai.client import MistralClient\n",
        "import markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGhh9IA1KIWn"
      },
      "source": [
        "### Utils - just for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q8YE3QkOKCk5"
      },
      "outputs": [],
      "source": [
        "%pip install -qU rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rhEUMf9AKFMR"
      },
      "outputs": [],
      "source": [
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.text import Text\n",
        "from rich.syntax import Syntax\n",
        "from rich.table import Table\n",
        "from typing import Any\n",
        "\n",
        "console = Console()\n",
        "def print_model_response(input_text: str, model_response: Any, model_name: str = \"assistant\") -> None:\n",
        "\n",
        "    # Input Panel\n",
        "    input_panel = Panel(\n",
        "        Text(input_text, style=\"blue\"), title=\"üìù Input Text\", border_style=\"blue\"\n",
        "    )\n",
        "\n",
        "    # Response Panel\n",
        "    if isinstance(model_response, dict):\n",
        "        table = Table(show_header=True, header_style=\"bold magenta\")\n",
        "        table.add_column(\"Key\", style=\"cyan\")\n",
        "        table.add_column(\"Value\", style=\"yellow\")\n",
        "\n",
        "        for key, value in model_response.items():\n",
        "            table.add_row(str(key), str(value))\n",
        "\n",
        "        response_content = table\n",
        "    else:\n",
        "        response_content = Text(str(model_response), style=\"yellow\")\n",
        "\n",
        "    response_panel = Panel(\n",
        "        response_content, title=model_name+\"ü§ñ Response\", border_style=\"magenta\"\n",
        "    )\n",
        "\n",
        "    console.print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "    console.print(input_panel)\n",
        "    console.print(response_panel)\n",
        "    console.print(\"\\n\" + \"=\" * 80 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXPzrJa9_SEo"
      },
      "source": [
        "### FIRST STEP: SET YOUR API-KEYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2TBQlOdz_GsS"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Mistral API Key\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    try:\n",
        "        os.environ[\"MISTRAL_API_KEY\"] = userdata.get('MISTRAL_API_KEY')\n",
        "    except Exception as e:\n",
        "        os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Provide your Mistral API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uCq9H5LABl4Z"
      },
      "outputs": [],
      "source": [
        "llm_mistral = ChatMistralAI(model=\"mistral-tiny\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiKbcQxzErEc"
      },
      "source": [
        "### PINECONE\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "https://www.pinecone.io/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YEzF35cPExvu"
      },
      "outputs": [],
      "source": [
        "if \"PINECONE_API_KEY\" not in os.environ:\n",
        "    try:\n",
        "        os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
        "    except Exception as e:\n",
        "        os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Provide your PINECONE API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G2hPj89kEtOx"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "spec = ServerlessSpec(\n",
        "    cloud='aws',\n",
        "    region='us-east-1'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lafl7k_qEtsQ",
        "outputId": "b3c3e250-9151-4acc-9150-bc1e6ffbcf5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_mistralai/embeddings.py:181: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding dimension: 1024\n"
          ]
        }
      ],
      "source": [
        "# Test embedding size\n",
        "llm = ChatMistralAI(model=\"mistral-tiny\", temperature=0)\n",
        "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
        "dim = len(embeddings.embed_query(\"test\"))\n",
        "print(f\"Embedding dimension: {dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O6xWc8oOHg1a"
      },
      "outputs": [],
      "source": [
        "# Crea/recupera indice\n",
        "index_name = \"academic-papers\"\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=dim,\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7u4uMWg8G3Zu"
      },
      "outputs": [],
      "source": [
        "with open('paper1.pdf', 'rb') as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LNIPvwFwIZ7E"
      },
      "outputs": [],
      "source": [
        "#Crea chunk (1000 caratteri con 200 di overlap)\n",
        "chunks = []\n",
        "chunk_size = 1000\n",
        "overlap = 200\n",
        "start = 0\n",
        "while start < len(text):\n",
        "    end = start + chunk_size\n",
        "    if end < len(text):\n",
        "        end = text.rfind(' ', start, end)\n",
        "    chunks.append(text[start:end].strip())\n",
        "    start = end - overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R7lLcSt0W91",
        "outputId": "5c1f517b-11ca-49ac-c7bd-9120ac8d2838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP_yklqk0bIq",
        "outputId": "39597852-cac7-47f7-b9e2-8d490c2ca0d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<p>Received 10 December 2024; accepted 15 December 2024. Date of publication 18 December 2024;\n",
            "date of current version 9 January 2025. The review of this article was arranged by Associate Editor Peng Li.\n",
            "Digital Object IdentiÔ¨Åer 10.1109/OJCS.2024.3519747\n",
            "Reducing Data Volume in News Topic\n",
            "ClassiÔ¨Åcation: Deep Learning Framework\n",
            "and Dataset\n",
            "LUIGI SERRELI1,2(Member, IEEE), CLAUDIO MARCHE1,2(Member, IEEE),\n",
            "AND MICHELE NITTI1,2(Senior Member, IEEE)\n",
            "1Department of Electrical and Electronic Engineering (DIEE), University of Cagliari, 09123 Cagliari, Italy\n",
            "2Research Unit of Cagliari, National Telecommunication Inter University Consortium 09123 Cagliari, Italy\n",
            "CORRESPONDING AUTHOR: LUIGI SERRELI (e-mail: luigi.serreli@unica.it).\n",
            "This work was supported by the Ministero dell‚ÄôIstruzione, dell‚ÄôUniversita e della Ricerca (MIUR) with the PON ‚ÄúRicerca e Innovazione‚Äù 2014-2020 (PO N RI)\n",
            "‚ÄúAzione IV.5 Dottorati su tematiche green‚Äù, assigned with D.M. 1062 on 10.08.2021.\n",
            "ABSTRACT Withthe rise of smart</p>\n"
          ]
        }
      ],
      "source": [
        "print(markdown.markdown(chunks[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GRyFrrx0zow",
        "outputId": "3c6f5bee-c2b4-4527-da00-d1848c9c0178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<p>ersita e della Ricerca (MIUR) with the PON ‚ÄúRicerca e Innovazione‚Äù 2014-2020 (PO N RI)\n",
            "‚ÄúAzione IV.5 Dottorati su tematiche green‚Äù, assigned with D.M. 1062 on 10.08.2021.\n",
            "ABSTRACT Withthe rise of smart devices and technological advancements, accessing vast amounts of infor-\n",
            "mation has become easier than ever before. However, sorting and categorising such an overwhelming volume\n",
            "of content has become increasingly challenging. This article introduces a new framework for classifying\n",
            "news articles based on a Bidirectional LSTM (BiLSTM) network and an attention mechanism. The article\n",
            "also presents a new dataset of 60 000 news articles from various global sources. Furthermore, it proposes a\n",
            "methodology for reducing data volume by extracting key sentences using an algorithm resulting in inference\n",
            "times that are, on average, 50% shorter than the original document without compromising the system‚Äôs\n",
            "accuracy. Experimental evaluations demonstrate that our framework outperforms existing</p>\n"
          ]
        }
      ],
      "source": [
        "print(markdown.markdown(chunks[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fg7kpxLBIwm-"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "27553536672a4c5993d0e0e3410e013f",
            "490ccdc4ac1c4a498ccde29f41febe13",
            "e547fb73657946a3b8192e0b7f65ae7f",
            "df711bbf66b940a5a3d4f9ccc256d6e5",
            "41e06174db8549b4a981741a4342fbcb",
            "906122309488499596cda0b59874554f",
            "509c039d1fe4423abe9eef44094a0fc6",
            "338361fbd33b414baa3f68a37e04ee8b",
            "11ecfd72a6c041b6865dde3b20500292",
            "516e42530541438ab1088f069a37de1f",
            "464d7bbdfe4a415aba9131389af0f743"
          ]
        },
        "id": "PQ92k_drIcqs",
        "outputId": "f366fe41-f586-41a9-ba0a-8c42613bf93a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27553536672a4c5993d0e0e3410e013f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Crea embeddings e Carica su PineCone\n",
        "batch_size = 10\n",
        "for i in tqdm(range(0, len(chunks), batch_size)):\n",
        "    # Prendi il batch corrente\n",
        "    batch = chunks[i:i+batch_size]\n",
        "    ids = [f\"chunk_{j}\" for j in range(i, i+len(batch))]\n",
        "\n",
        "    # Crea embeddings con pausa tra ogni chiamata\n",
        "    embeddings_batch = []\n",
        "    for chunk in batch:\n",
        "        emb = embeddings.embed_query(chunk)\n",
        "        embeddings_batch.append(emb)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Upsert su Pinecone\n",
        "    vectors = list(zip(ids, embeddings_batch, [{\"text\": text} for text in batch]))\n",
        "    index.upsert(vectors=vectors)\n",
        "    time.sleep(2)  # 1 secondo di pausa tra i batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WZ9bLwVKMBk"
      },
      "source": [
        "Let us make a question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_lTbIt5cInfr"
      },
      "outputs": [],
      "source": [
        "\n",
        "query = \"What are the main contributions of the paper?\"\n",
        "query_embedding = embeddings.embed_query(query)\n",
        "time.sleep(0.5)\n",
        "\n",
        "results = index.query(vector=query_embedding, top_k=3, include_metadata=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyweuOdD6J5R",
        "outputId": "980344f4-9920-4a04-8dd4-c7fdff05d80b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': 'chunk_74',\n",
              "              'metadata': {'text': '‚ÄúSemisupervised learning-based\\n'\n",
              "                                   'word-sense disambiguation using word '\n",
              "                                   'embedding for afaan oro-\\n'\n",
              "                                   'moo language,‚Äù Appl. Comput. Intell. Soft '\n",
              "                                   'Comput. , vol. 2024, 2024,\\n'\n",
              "                                   'Art. no. 4429069.\\n'\n",
              "                                   '[29] K. Patel and P. Bhattacharyya, '\n",
              "                                   '‚ÄúTowards lower bounds on number of\\n'\n",
              "                                   'dimensions for word embeddings,‚Äù in Proc. '\n",
              "                                   '8th Int. Joint Conf. Nat-\\n'\n",
              "                                   'ural Lang. Process. , G. Kondrak and T. '\n",
              "                                   'Watanabe, Eds., Nov. 2017,\\n'\n",
              "                                   'pp. 31‚Äì36.\\n'\n",
              "                                   '[30] K. Schr√∏der, ‚ÄúWhat do news readers '\n",
              "                                   'really want to read about? how\\n'\n",
              "                                   'relevance works for news audiences,‚Äù '\n",
              "                                   'Digit. News Project , pp. 1‚Äì36,\\n'\n",
              "                                   '2019, doi: 10.60625/risj-n12y-az27 .\\n'\n",
              "                                   '[31] G. M. Del Corso, A. Gulli, and F. '\n",
              "                                   'Romani, ‚ÄúRanking a stream of news,‚Äù\\n'\n",
              "                                   'inProc. 14th Int. Conf. World Wide Web , '\n",
              "                                   'New York, NY, USA, 2005,\\n'\n",
              "                                   'pp. 97‚Äì106.\\n'\n",
              "                                   '[32] D. Greene and P. Cunningham, '\n",
              "                                   '‚ÄúPractical solutions to the problem of\\n'\n",
              "                                   'diagonal dominance in kernel document '\n",
              "                                   'clustering,‚Äù in Proc. 23rd Int.\\n'\n",
              "                                   'Conf. Mach. Learn. , 2006, pp. 377‚Äì384.\\n'\n",
              "                                   '[33] Reuters, ‚ÄúReuters-21578 text '\n",
              "                                   'categorization collection,‚Äù 1987. Ac-\\n'\n",
              "                                   'cessed: Dec. 01,'},\n",
              "              'score': 0.713833809,\n",
              "              'values': []},\n",
              "             {'id': 'chunk_25',\n",
              "              'metadata': {'text': 'To provide a comprehensive overview of\\n'\n",
              "                                   'the related works, we have summarised the '\n",
              "                                   'previous studies\\n'\n",
              "                                   'in Table 1.\\n'\n",
              "                                   'III. PROPOSED SOLUTION\\n'\n",
              "                                   'In this section, we Ô¨Årst mathematically '\n",
              "                                   'deÔ¨Åne the problem\\n'\n",
              "                                   'and then provide an overview of the '\n",
              "                                   'processes to reach the\\n'\n",
              "                                   'results presented in Section VI. The '\n",
              "                                   'process has been split intoTABLE 1. Topic '\n",
              "                                   'ClassiÔ¨Åcation Works - Summary of '\n",
              "                                   'Approaches, Features,\\n'\n",
              "                                   'and Datasets\\n'\n",
              "                                   'three distinct phases: Key Sentence '\n",
              "                                   'Extractor (KSE), word\\n'\n",
              "                                   'embedding, and Ô¨Ånally, the topic '\n",
              "                                   'classiÔ¨Åer.\\n'\n",
              "                                   'A. PROBLEM DEFINITION\\n'\n",
              "                                   'The automatic classiÔ¨Åcation branch '\n",
              "                                   'encompasses various\\n'\n",
              "                                   'forms of data, including video, audio '\n",
              "                                   '[25], images [26], and\\n'\n",
              "                                   'text. Among them, our article focuses on '\n",
              "                                   'classifying textual\\n'\n",
              "                                   'data, speciÔ¨Åcally news articles on the '\n",
              "                                   'web. In our modelling,\\n'\n",
              "                                   'each document diis decomposed into '\n",
              "                                   'sentences, deÔ¨Åned as a\\n'\n",
              "                                   'setSi={si1,si2,..., siy,..., siMi}, where '\n",
              "                                   'Mirepresents the\\n'\n",
              "                                   'number of sentences in the i-th document. '\n",
              "                                   'Each sentence\\n'\n",
              "                                   'siyconsists of a set '\n",
              "                                   'Wiy={wiy1,...,wiyz,...,wiyZiy}ofZiy\\n'\n",
              "                                   'words,'},\n",
              "              'score': 0.706913888,\n",
              "              'values': []},\n",
              "             {'id': 'chunk_1',\n",
              "              'metadata': {'text': 'ersita e della Ricerca (MIUR) with the PON '\n",
              "                                   '‚ÄúRicerca e Innovazione‚Äù 2014-2020 (PO N '\n",
              "                                   'RI)\\n'\n",
              "                                   '‚ÄúAzione IV.5 Dottorati su tematiche '\n",
              "                                   'green‚Äù, assigned with D.M. 1062 on '\n",
              "                                   '10.08.2021.\\n'\n",
              "                                   'ABSTRACT Withthe rise of smart devices and '\n",
              "                                   'technological advancements, accessing vast '\n",
              "                                   'amounts of infor-\\n'\n",
              "                                   'mation has become easier than ever before. '\n",
              "                                   'However, sorting and categorising such an '\n",
              "                                   'overwhelming volume\\n'\n",
              "                                   'of content has become increasingly '\n",
              "                                   'challenging. This article introduces a new '\n",
              "                                   'framework for classifying\\n'\n",
              "                                   'news articles based on a Bidirectional '\n",
              "                                   'LSTM (BiLSTM) network and an attention '\n",
              "                                   'mechanism. The article\\n'\n",
              "                                   'also presents a new dataset of 60 000 news '\n",
              "                                   'articles from various global sources. '\n",
              "                                   'Furthermore, it proposes a\\n'\n",
              "                                   'methodology for reducing data volume by '\n",
              "                                   'extracting key sentences using an '\n",
              "                                   'algorithm resulting in inference\\n'\n",
              "                                   'times that are, on average, 50% shorter '\n",
              "                                   'than the original document without '\n",
              "                                   'compromising the system‚Äôs\\n'\n",
              "                                   'accuracy. Experimental evaluations '\n",
              "                                   'demonstrate that our framework outperforms '\n",
              "                                   'existing'},\n",
              "              'score': 0.70599252,\n",
              "              'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSD3ASM7Kx1I"
      },
      "source": [
        "Get a response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKZRVcw9J1c7",
        "outputId": "2b719368-fe7c-4ba5-c05c-7106bf699954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"The main contributions of the paper, as outlined in the context, are:\\n\\n1. Proposing a new framework for classifying news articles based on a Bidirectional LSTM (BiLSTM) network and an attention mechanism.\\n2. Introducing a new dataset of 60,000 news articles from various global sources.\\n3. Developing a methodology for reducing data volume by extracting key sentences using an algorithm, resulting in inference times that are, on average, 50% shorter than the original document without compromising the system's accuracy.\\n\\nThe paper claims that this framework outperforms existing methods.\" additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 1019, 'total_tokens': 1156, 'completion_tokens': 137}, 'model': 'mistral-tiny', 'finish_reason': 'stop'} id='run-5c039fce-8e20-411f-9216-855ad24efc68-0' usage_metadata={'input_tokens': 1019, 'output_tokens': 137, 'total_tokens': 1156}\n"
          ]
        }
      ],
      "source": [
        "context = [match.metadata[\"text\"] for match in results.matches]\n",
        "prompt = f\"\"\"Given the context, Try answering the question.\n",
        "If the response is not in the context, say it explicitly.\n",
        "\n",
        "Context:\n",
        "{' '.join(context)}\n",
        "\n",
        "Question: {query}\n",
        "\"\"\"\n",
        "response = llm_mistral.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chilk4s4PNVP"
      },
      "source": [
        "### RAG and CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mk3o1msPPLS"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from pathlib import Path\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4d3oeeDRRl7"
      },
      "outputs": [],
      "source": [
        "!pip install -q kagglehub\n",
        "!pip install -q faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBntrkzlRY1T"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"amirkaviani0/customers-100\")\n",
        "path = path+\"/customers-100.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvmL2c3rRmjA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd4DooSDSHqc"
      },
      "outputs": [],
      "source": [
        "loader = CSVLoader(file_path=path)\n",
        "docs = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6Q4Jvy7gdiy"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl5gOEjwPYZ0"
      },
      "outputs": [],
      "source": [
        "llm = ChatMistralAI(model=\"mistral-tiny\", temperature=0)\n",
        "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C6m4EFCQEXJ"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "index = faiss.IndexFlatL2(len(embeddings.embed_query(\" \")))\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9oQWAtHSmq_"
      },
      "outputs": [],
      "source": [
        "vector_store.add_documents(documents=docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egV0XIvcS8fP"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzSRxxD_TcVl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# Define the system prompt with a clear instruction for the assistant\n",
        "system_prompt = (\n",
        "    \"You are an AI assistant designed to answer questions. \"\n",
        "    \"Utilize the provided context to formulate your response. \"\n",
        "    \"If the context does not contain enough information to answer the question, \"\n",
        "    \"simply state that you do not know. Keep your response concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "# Create a ChatPromptTemplate with the system prompt and user input\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),  # System message with instructions\n",
        "    (\"human\", \"{input}\"),       # User's question or input\n",
        "])\n",
        "\n",
        "# Create a chain that processes documents and generates answers\n",
        "document_processing_chain = create_stuff_documents_chain(llm, chat_prompt)\n",
        "\n",
        "# Combine the document processing chain with a retriever to form the RAG chain\n",
        "rag_chain = create_retrieval_chain(retriever, document_processing_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxBTuHv8TlTt"
      },
      "outputs": [],
      "source": [
        "answer= rag_chain.invoke({\"input\": \"Tell me all you know about Linda\tOlsen\"})\n",
        "answer['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd-FDI1ugs0N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjMASzEyknlQ"
      },
      "source": [
        "### Slower Approach (if you get \"too many requests\" error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txymTf4vhXH6"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "dimension = len(embeddings.embed_query(\"\"))\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "all_embeddings = []\n",
        "for doc in tqdm(docs):\n",
        "    embedding = embeddings.embed_query(doc.page_content)\n",
        "    time.sleep(2)\n",
        "    all_embeddings.append(embedding)\n",
        "\n",
        "embeddings_array = np.array(all_embeddings).astype('float32')\n",
        "index.add(embeddings_array)\n",
        "\n",
        "# Crea il vector store\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u6sNMzOjyy4"
      },
      "outputs": [],
      "source": [
        "vector_store = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzhYS9kji_4k"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEiUyagRjJCi"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# Define the system prompt with a clear instruction for the assistant\n",
        "system_prompt = (\n",
        "    \"You are an AI assistant designed to answer questions. \"\n",
        "    \"Utilize the provided context to formulate your response. \"\n",
        "    \"If the context does not contain enough information to answer the question, \"\n",
        "    \"simply state that you do not know. Keep your response concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "# Create a ChatPromptTemplate with the system prompt and user input\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),  # System message with instructions\n",
        "    (\"human\", \"{input}\"),       # User's question or input\n",
        "])\n",
        "\n",
        "# Create a chain that processes documents and generates answers\n",
        "document_processing_chain = create_stuff_documents_chain(llm, chat_prompt)\n",
        "\n",
        "# Combine the document processing chain with a retriever to form the RAG chain\n",
        "rag_chain = create_retrieval_chain(retriever, document_processing_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8usz0C9jLT8"
      },
      "outputs": [],
      "source": [
        "answer= rag_chain.invoke({\"input\": \"Tell me all you know about Linda\tOlsen\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uavxADYBjTTy"
      },
      "outputs": [],
      "source": [
        "answer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11ecfd72a6c041b6865dde3b20500292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27553536672a4c5993d0e0e3410e013f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_490ccdc4ac1c4a498ccde29f41febe13",
              "IPY_MODEL_e547fb73657946a3b8192e0b7f65ae7f",
              "IPY_MODEL_df711bbf66b940a5a3d4f9ccc256d6e5"
            ],
            "layout": "IPY_MODEL_41e06174db8549b4a981741a4342fbcb"
          }
        },
        "338361fbd33b414baa3f68a37e04ee8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e06174db8549b4a981741a4342fbcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464d7bbdfe4a415aba9131389af0f743": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "490ccdc4ac1c4a498ccde29f41febe13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906122309488499596cda0b59874554f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_509c039d1fe4423abe9eef44094a0fc6",
            "value": "100%"
          }
        },
        "509c039d1fe4423abe9eef44094a0fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "516e42530541438ab1088f069a37de1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906122309488499596cda0b59874554f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df711bbf66b940a5a3d4f9ccc256d6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_516e42530541438ab1088f069a37de1f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_464d7bbdfe4a415aba9131389af0f743",
            "value": "‚Äá8/8‚Äá[03:36&lt;00:00,‚Äá26.96s/it]"
          }
        },
        "e547fb73657946a3b8192e0b7f65ae7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_338361fbd33b414baa3f68a37e04ee8b",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11ecfd72a6c041b6865dde3b20500292",
            "value": 8
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
